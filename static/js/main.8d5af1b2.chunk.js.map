{"version":3,"sources":["Images/newsmaller.jpg","Components/NavBar.js","Components/Title.js","Components/Skills.js","Downloads/Benjamin_Jordan_Resume_2025.pdf","Images/IMG_0426.JPEG","Components/ImageSection.js","Pages/AboutPage.js","Components/MenuItem.js","Images/audiocraft1.png","Images/dslabs1.PNG","Images/dslabs2.png","Images/SynthLM3.PNG","Images/SynthLM4.PNG","Images/SAE1.PNG","Images/SAE2.PNG","Images/SAE4.PNG","Images/ITP1.PNG","Images/ITP2.PNG","Images/ITP3.PNG","Images/ITP4.PNG","Images/GNN1.PNG","Images/GNN2.png","Images/EQ2.PNG","Images/OMNI1.PNG","Images/OMNI2.PNG","Images/OMNI4.PNG","Images/FV3.PNG","Images/layer2_feat2.png","Images/FV5.png","Images/clarinet-dry.mp3","Images/clarinet-wet.mp3","Images/clarinet-wet2.mp3","Images/eq-dry.mp3","Images/eq-wet.mp3","Images/dit.png","Images/frontend.PNG","Images/IMG_8809.JPEG","Components/ProjectDescriptions.js","Components/ProjectList.js","Pages/ProjectsPage.js","Pages/ContactPage.js","Components/ScrollToTop.js","App.js","index.js"],"names":["NavBar","_jsx","className","children","_jsxs","target","href","FontAwesomeIcon","icon","faGithub","faLinkedin","NavLink","to","exact","activeClassName","Title","_ref","title","progress","a","style","animation","Skills","ImageSection","src","profilePic","alt","AboutPage","color","resume","download","MenuItem","menuItem","id","linkify","setId","text","test","replace","match","prefix","rawUrl","url","trailing","slice","length","concat","_useState","useState","_useState2","_slicedToArray","expanded","map","item","maxHeight","dangerouslySetInnerHTML","__html","descriptions","images","imagecap","synthlm1","synthlm2","synthlm3","synthlm4","synthlm5","synthlm6","synthlm7","portfolios","category","link","faChrome","audiocraft1","dit","pc","cats","i","push","allCategories","_toConsumableArray","filter","value","index","array","indexOf","ProjectsPage","_useState3","_useState4","menuItems","_useState5","_useState6","ContactPage","_useForm","useForm","_useForm2","state","succeeded","document","getElementsByClassName","display","getElementById","reset","width","height","border","allowFullScreen","loading","referrerPolicy","ScrollToTop","pathname","useLocation","useEffect","window","scrollTo","App","navToggle","Switch","Route","path","FaArrowRight","FaArrowLeft","ReactDOM","render","React","StrictMode","HashRouter"],"mappings":"iZAAe,I,4BCgEAA,MA1Df,WACI,OACIC,cAAA,OAAKC,UAAU,SAAQC,SACnBC,eAAA,OAAKF,UAAU,MAAKC,SAAA,CAChBF,cAAA,UAAQC,UAAU,OAAMC,SASpBC,eAAA,OAAKF,UAAU,QAAOC,SAAA,CAClBF,cAAA,KAAGI,OAAS,SAASC,KAAO,kCAAkCJ,UAAU,YAAWC,SAC/EF,cAACM,IAAe,CAACC,KAAQC,IAAUP,UAAU,WAEjDD,cAAA,KAAGI,OAAS,SAAUC,KAAO,oDAAoDJ,UAAU,YAAWC,SAClGF,cAACM,IAAe,CAACC,KAAQE,IAAYR,UAAU,gBAK3DE,eAAA,MAAIF,UAAU,YAAWC,SAAA,CACrBF,cAAA,OAAKC,UAAU,WAAUC,SACrBF,cAACU,IAAO,CAACC,GAAG,IAAIC,OAAK,EAACC,gBAAgB,SAAQX,SAAC,WASnDF,cAAA,OAAKC,UAAU,WAAUC,SACrBF,cAACU,IAAO,CAACC,GAAG,YAAYC,OAAK,EAACC,gBAAgB,SAAQX,SAAC,eAI3DF,cAAA,OAAKC,UAAU,WAAUC,SACrBF,cAACU,IAAO,CAACC,GAAG,WAAWC,OAAK,EAACC,gBAAgB,SAAQX,SAAC,iBAO9DF,cAAA,OAAKC,UAAU,gBAAeC,SAC1BF,cAAA,KAAAE,SAAG,6BCvBRY,MA7Bf,SAAcC,GAAqB,IAAnBC,EAAKD,EAALC,MAAOC,EAAQF,EAARE,SACfC,EAAI,4BAeR,OAdgB,KAAbD,EAECC,EAAI,4BAEa,KAAbD,EAEJC,EAAI,4BAEa,MAAbD,IAEJC,EAAI,8BAKJf,eAAA,OAAKF,UAAU,QAAOC,SAAA,CAClBF,cAAA,OAAKC,UAAU,WAAUC,SACrBF,cAAA,OAAKC,UAAU,oBAAoBkB,MAAO,CAACC,UAAWF,OAE1Df,eAAA,MAAAD,SAAA,CACKc,EACDhB,cAAA,QAAAE,SAAOc,WCLRK,ICpBA,MAA0B,wDCA1B,MAA0B,sCCkC1BC,MA9Bf,WACI,OACItB,cAAA,OAAKC,UAAU,eAAcC,SACzBC,eAAA,OAAKF,UAAU,gBAAeC,SAAA,CAC1BF,cAAA,OAAKC,UAAU,aAAYC,SACvBC,eAAA,KAAGF,UAAU,aAAYC,SAAA,CACrBF,cAAA,QAAAE,SAAM,kFACNF,cAAA,SAAKA,cAAA,SAAK,sMAGVA,cAAA,SAAKA,cAAA,SAAK,2PAKlBA,cAAA,OAAKC,UAAU,oBAAmBC,SAC9BF,cAAA,OACIuB,IAAKC,EACLC,IAAI,2BACJxB,UAAU,sBCJnByB,MAbf,WACI,OACIvB,eAAA,OAAKF,UAAU,YAAWC,SAAA,CACtBF,cAACc,EAAK,CAACE,MAAO,aAAcC,SAAU,KACtCjB,cAACsB,EAAY,IACbtB,cAACc,EAAK,CAACE,MAAO,KAAMC,SAAU,KAC9BjB,cAAA,KAAGC,UAAU,gBAAgBkB,MAAO,CAACQ,MAAO,sBAAuBtB,KAAMuB,EAAQC,UAAQ,EAAA3B,SACrFF,cAAA,UAAQC,UAAU,MAAKC,SAAC,mB,qBCoIzB4B,MA3If,SAAiBf,GAAyB,IAAvBgB,EAAQhB,EAARgB,SAAUC,EAAEjB,EAAFiB,GACnBC,GAD4BlB,EAALmB,MACb,SAACC,GACb,OAAKA,EAED,cAAcC,KAAKD,GAAcA,EAE9BA,EAAKE,QAAQ,uCAAuC,SAACC,EAAOC,EAAQC,GACvE,IAAMC,EAAMD,EAAOH,QAAQ,YAAa,IAClCK,EAAWF,EAAOG,MAAMF,EAAIG,QAClC,MAAM,GAANC,OAAUN,EAAM,aAAAM,OAAYJ,EAAG,gDAAAI,OAA+CJ,EAAG,QAAAI,OAAOH,MAP1E,KAUtBI,EAAgCC,oBAAS,GAAKC,EAAAC,YAAAH,EAAA,GAAvCI,EAAQF,EAAA,GACf,OAD4BA,EAAA,GAExBhD,cAAA,OAAKC,UAAS,WAAaC,SAEnB6B,EAASoB,KAAI,SAACC,GAEV,OAAOjD,eAAA,OAAKF,UAAS,YAAcC,SAAA,CAC/BF,cAAA,MAAAE,SAIIF,cAAA,OAAKC,UAAU,QAAOC,SACjBkD,EAAKpC,UAIdb,eAAA,OAAKgB,MAAO,CAACkC,UAAU,GAADR,QAAKK,IAAqB,IAARlB,GAAaoB,EAAKpB,KAAOA,EAAgB,OAAV,UAAqB/B,UAAS,kBAAoBC,SAAA,CACrHF,cAAA,OAAKC,UAAS,GAAA4C,QAAKK,IAAqB,IAARlB,GAAaoB,EAAKpB,KAAOA,EAA0B,aAArB,sBAa9D7B,eAAA,OAAKF,UAAU,iBAAgBC,SAAA,CAC3BF,cAAA,KAAGC,UAAU,cAAcqD,wBAAyB,CAChDC,OAAQtB,EAAQmB,EAAKI,cAAgBJ,EAAKI,aAAa,IAAY,OAErE,WACM,GAAIJ,EAAKK,QAAUL,EAAKK,OAAO,GAC3B,OAAOtD,eAAA,OAAAD,SAAA,CACHF,cAAA,OAAKC,UAAU,MACVsB,IAAK6B,EAAKK,OAAO,GACjBhC,IAAI,KACTzB,cAAA,OACIC,UAAU,cAAaC,SAAEkD,EAAKM,SAAS,QAPzD,GAYF1D,cAAA,KAAGC,UAAU,cAAcqD,wBAAyB,CAChDC,OAAQtB,EAAQmB,EAAKI,cAAgBJ,EAAKI,aAAa,IAAY,OAsBvExD,cAAA,KAAGC,UAAU,cAAcqD,wBAAyB,CAChDC,OAAQtB,EAAQmB,EAAKI,cAAgBJ,EAAKI,aAAa,IAAY,OAErE,WACM,GAAIJ,EAAKK,QAAUL,EAAKK,OAAO,GAC3B,OAAOtD,eAAA,OAAAD,SAAA,CACHF,cAAA,OAAKC,UAAU,MACVsB,IAAK6B,EAAKK,OAAO,GACjBhC,IAAI,KACTzB,cAAA,OAAKC,UAAU,cAAaC,SAAEkD,EAAKM,SAAS,QAN1D,GAWF1D,cAAA,KAAGC,UAAU,cAAcqD,wBAAyB,CAChDC,OAAQtB,EAAQmB,EAAKI,cAAgBJ,EAAKI,aAAa,IAAY,OAGvExD,cAAA,KAAGC,UAAU,cAAcqD,wBAAyB,CAChDC,OAAQtB,EAAQmB,EAAKI,cAAgBJ,EAAKI,aAAa,IAAY,OAEvExD,cAAA,KAAGC,UAAU,cAAcqD,wBAAyB,CAChDC,OAAQtB,EAAQmB,EAAKI,cAAgBJ,EAAKI,aAAa,IAAY,OAEvExD,cAAA,KAAGC,UAAU,cAAcqD,wBAAyB,CAChDC,OAAQtB,EAAQmB,EAAKI,cAAgBJ,EAAKI,aAAa,IAAY,OAErE,WACM,GAAIJ,EAAKK,QAAUL,EAAKK,OAAO,GAC3B,OAAOtD,eAAA,OAAAD,SAAA,CACHF,cAAA,OAAKC,UAAU,MACVsB,IAAK6B,EAAKK,OAAO,GACjBhC,IAAI,KACTzB,cAAA,OAAKC,UAAU,cAAaC,SAAEkD,EAAKM,SAAS,QAN1D,GAWA,WACM,GAAIN,EAAKK,QAAUL,EAAKK,OAAO,GAC3B,OAAOtD,eAAA,OAAAD,SAAA,CACHF,cAAA,OAAKC,UAAU,MACVsB,IAAK6B,EAAKK,OAAO,GACjBhC,IAAI,KACTzB,cAAA,OAAKC,UAAU,cAAaC,SAAEkD,EAAKM,SAAS,QAN1D,WArG2BN,EAAKpB,UCxBnD,GCAA,ICAA,ICAA,ICAA,ICAA,ICAA,ICAA,ICAA,ICAA,ICAA,ICAA,ICAA,ICAA,ICAA,ICAA,ICAA,ICAA,ICAA,ICAA,ICAA,ICAA,ICAA,ICAA,ICAA,ICAA,IzBAA,IAA0B,yC0BA1B,GCAA,IDAA,IAA0B,iCEA1B,MAA0B,sCC8M1BwB,EA7MX,CACIG,SAAU,gkBAMVC,SAAU,i5BAQVC,SAAU,qxBAMVC,SAAU,2oCASVC,SAAU,kjDAUVC,SAAU,woBAMVC,SAAU,gmBCuGHC,EAjHI,CACf,CACIlC,GAAI,EACJmC,SAAU,CAAC,QACXC,KAAM,2BACN7D,KAAM8D,IACNb,aAAc,CAACA,EAAaG,SAAUH,EAAaI,SAAUJ,EAAaK,SAAUL,EAAaM,SAC/FN,EAAaO,SAAUP,EAAaQ,SAAUR,EAAaS,UAC7DjD,MAAO,6DACPyC,OAAQ,CAACa,EAAaC,EAAKC,GAC3Bd,SAAU,CAAC,qCAAsC,uCAAwC,yBCrCjG,IAAIe,EAAO,GACXP,EAAWf,KAAI,SAAAC,GAAI,OAAIA,EAAKe,SAAShB,KAAI,SAAAuB,GAAC,OAAID,EAAKE,KAAKD,SACxD,IAAIE,EAAa,CAAI,OAAK/B,OAAAgC,YAAKJ,EAAKK,QALpC,SAAoBC,EAAOC,EAAOC,GAC9B,OAAOA,EAAMC,QAAQH,KAAWC,OAqCrBG,MAhCf,WACI,IAAArC,EAAoCC,mBAAS6B,GAAc5B,EAAAC,YAAAH,EAAA,GAC3DsC,GADiBpC,EAAA,GAAeA,EAAA,GACED,mBAASmB,IAAWmB,EAAApC,YAAAmC,EAAA,GAA/CE,EAASD,EAAA,GAChBE,GAD8BF,EAAA,GACVtC,oBAAU,IAAEyC,EAAAvC,YAAAsC,EAAA,GAAzBvD,EAAEwD,EAAA,GAAEtD,EAAKsD,EAAA,GAgBhB,OACIrF,eAAA,OAAKF,UAAU,eAAcC,SAAA,CACzBF,cAAA,OAAKC,UAAU,QAAOC,SAClBF,cAACc,EAAK,CAACE,MAAO,gBAAiBC,SAAU,OAE7CjB,cAAA,OAAKC,UAAU,iBAAgBC,SAE3BF,cAAC8B,EAAQ,CAACC,SAAUuD,EAAWtD,GAAIA,EAAIE,MAAOA,U,QCuB/CuD,MA1Df,WACI,IAAAC,EAA8BC,YAAQ,YAAWC,EAAA3C,YAAAyC,EAAA,GAA1CG,EAAKD,EAAA,GAKZ,OAL0BA,EAAA,GACtBC,EAAMC,YACNC,SAASC,uBAAuB,WAAW,GAAG7E,MAAM8E,QAAU,OAC9DF,SAASG,eAAe,gBAAgBC,SAGxChG,eAAA,OAAKF,UAAU,cAAaC,SAAA,CACxBF,cAAA,OAAKC,UAAU,gBAAeC,SAC1BF,cAACc,EAAK,CAACE,MAAO,UAAWC,SAAU,QAEvCd,eAAA,OAAKF,UAAU,WAAUC,SAAA,CACrBC,eAAA,OAAKF,UAAU,eAAcC,SAAA,CAAC,sBAE1BF,cAAA,SAAKA,cAAA,SAAK,+CAEVA,cAAA,SAAKA,cAAA,SAAK,oCAGdA,cAAA,OAAKC,UAAU,WAAUC,SACrBF,cAAA,UACIuB,IAAI,kRACJ6E,MAAM,MACNC,OAAO,MACPlF,MAAO,CAAEmF,OAAQ,GACjBC,gBAAgB,GAChBC,QAAQ,OACRC,eAAe,wC,QC5BxB,SAASC,IACpB,IAAQC,EAAaC,cAAbD,SAMR,OAJAE,qBAAU,WACNC,OAAOC,SAAS,EAAG,KACpB,CAACJ,IAEG,KCgGIK,MAvFf,WACI,IAAAlE,EAAkCC,oBAAS,GAAMC,EAAAC,YAAAH,EAAA,GAA1CmE,EAASjE,EAAA,GASlB,OATgCA,EAAA,GAU9B7C,eAAA,OAAKF,UAAU,MAAKC,SAAA,CAChBF,cAAA,OAAKC,UAAU,OAAMC,SACjBC,eAAC+G,IAAM,CAAAhH,SAAA,CACHF,cAACmH,IAAK,CAACC,KAAK,IAAIxG,OAAK,EAAAV,SACjBC,eAACO,IAAO,CAACT,UAAY,aAAaU,GAAG,YAAYC,OAAK,EAAAV,SAAA,CAClDF,cAACqH,IAAY,IACbrH,cAACqH,IAAY,CAACpH,UAAY,qBAelCE,eAACgH,IAAK,CAACC,KAAK,YAAYxG,OAAK,EAAAV,SAAA,CACzBC,eAACO,IAAO,CAACT,UAAY,YAAYU,GAAG,IAAIC,OAAK,EAAAV,SAAA,CACzCF,cAACsH,IAAW,IACZtH,cAACsH,IAAW,CAACrH,UAAY,kBAE7BE,eAACO,IAAO,CAACT,UAAY,aAAaU,GAAG,WAAWC,OAAK,EAAAV,SAAA,CACjDF,cAACqH,IAAY,IACbrH,cAACqH,IAAY,CAACpH,UAAY,sBAIlCD,cAACmH,IAAK,CAACC,KAAK,WAAWxG,OAAK,EAAAV,SACxBC,eAACO,IAAO,CAACT,UAAY,YAAYU,GAAG,YAAYC,OAAK,EAAAV,SAAA,CACjDF,cAACsH,IAAW,IACZtH,cAACsH,IAAW,CAACrH,UAAY,yBAS3CD,cAAA,OAAKC,UAAS,WAAA4C,OAAaoE,EAAY,aAAc,IAAK/G,SACxDF,cAACD,EAAM,MAETC,cAAA,OAAKC,UAAU,eAAcC,SAC3BF,cAAA,OAAKC,UAAU,UAASC,SACpBC,eAAC+G,IAAM,CAAAhH,SAAA,CAMHC,eAACgH,IAAK,CAACC,KAAK,IAAIxG,OAAK,EAAAV,SAAA,CACjBF,cAAC0G,EAAW,IACZ1G,cAAC0B,EAAS,OAGdvB,eAACgH,IAAK,CAACC,KAAK,YAAYxG,OAAK,EAAAV,SAAA,CACzBF,cAAC0G,EAAW,IACZ1G,cAACmF,EAAY,OAGjBhF,eAACgH,IAAK,CAACC,KAAK,WAAWxG,OAAK,EAAAV,SAAA,CACxBF,cAAC0G,EAAW,IACZ1G,cAACyF,EAAW,kBC5FhC8B,IAASC,OACPxH,cAACyH,IAAMC,WAAU,CAAAxH,SACfF,cAAC2H,IAAU,CAAAzH,SACPF,cAACgH,EAAG,QAGVjB,SAASG,eAAe,W","file":"static/js/main.8d5af1b2.chunk.js","sourcesContent":["export default __webpack_public_path__ + \"static/media/newsmaller.c434568e.jpg\";","import React from 'react';\nimport avatar from '../Images/newsmaller.jpg';\nimport {NavLink} from 'react-router-dom';\nimport {FontAwesomeIcon} from \"@fortawesome/react-fontawesome\";\nimport {faGithub, faLinkedin} from \"@fortawesome/free-brands-svg-icons\";\n\nfunction NavBar() {\n    return (\n        <div className=\"NavBar\">\n            <nav className=\"nav\">\n                <header className=\"hero\">\n                    {/*<h1 className=\"hero-text\">*/}\n                    {/*    <span> Ben Jordan</span>*/}\n                    {/*</h1>*/}\n\n                    {/*<p className=\"home-sub-text\">*/}\n                    {/*    Machine Learning & Software Engineering*/}\n                    {/*</p>*/}\n\n                    <div className=\"icons\">\n                        <a target = \"_blank\" href = \"https://github.com/EntropyAudio\" className=\"icon-link\">\n                            <FontAwesomeIcon icon = {faGithub} className=\"icon\"/>\n                        </a>\n                        <a target = \"_blank\"  href = \"https://www.linkedin.com/in/ben-jordan-b745a0194/\" className=\"icon-link\">\n                            <FontAwesomeIcon icon = {faLinkedin} className=\"icon\"/>\n                        </a>\n                    </div>\n                </header>\n\n                <ul className=\"nav-items\">\n                    <lin className=\"nav-item\">\n                        <NavLink to=\"/\" exact activeClassName=\"active\">\n                            Home\n                        </NavLink>\n                    </lin>\n                    {/*<lin className=\"nav-item\">*/}\n                    {/*    <NavLink to=\"/About\" exact activeClassName=\"active\">*/}\n                    {/*        About*/}\n                    {/*    </NavLink>*/}\n                    {/*</lin>*/}\n                    <lin className=\"nav-item\">\n                        <NavLink to=\"/Projects\" exact activeClassName=\"active\">\n                            Projects\n                        </NavLink>\n                    </lin>\n                    <lin className=\"nav-item\">\n                        <NavLink to=\"/Contact\" exact activeClassName=\"active\">\n                            Contact\n                        </NavLink>\n                    </lin>\n                </ul>\n                {/*<div className=\"footer footer\">*/}\n                {/*</div>*/}\n                <div className=\"footer footer\">\n                    <p>\n                        @2025 Ben Jordan\n                    </p>\n                </div>\n\n            </nav>\n        </div>\n    )\n}\n\nexport default NavBar;\n","import React from 'react';\n\nfunction Title({title, progress}) {\n    let a = \"title25 .9s ease forwards\";\n    if(progress === 50)\n    {\n        a = \"title50 .9s ease forwards\";\n    }\n    else if(progress === 75)\n    {\n        a = \"title75 .9s ease forwards\"\n    }\n    else if(progress === 100)\n    {\n        a = \"title100 .9s ease forwards\"\n    }\n\n\n    return (\n        <div className=\"Title\">\n            <div className=\"page-bar\">\n                <div className=\"page-bar-progress\" style={{animation: a}}/>\n            </div>\n            <h3>\n                {title}\n                <span>{title}</span>\n            </h3>\n        </div>\n    );\n}\n\nexport default Title;\n","import React from 'react';\n\nfunction Skills({skill, progress}) {\n    return (\n        <div className=\"Skills\">\n            <div className=\"skills-container\">\n                <h5 className=\"skill-title\">{skill}</h5>\n                {/*<div className=\"skill-bar\">*/}\n                {/*    <p className=\"skill-text\">{progress}</p>*/}\n                {/*    <div className=\"skill-progress\">*/}\n                {/*        <div className=\"progressbar\">*/}\n                {/*            <div className=\"inner-progress\" style={{width: progress}}>*/}\n                {/*            </div>*/}\n                {/*        </div>*/}\n                {/*    </div>*/}\n                {/*</div>*/}\n            </div>\n        </div>\n    );\n}\nexport default Skills;\n","export default __webpack_public_path__ + \"static/media/Benjamin_Jordan_Resume_2025.e306a5a8.pdf\";","export default __webpack_public_path__ + \"static/media/IMG_0426.2b35c307.JPEG\";","import React from 'react';\nimport resume from \"../Downloads/Benjamin_Jordan_Resume_2025.pdf\";\nimport profilePic from \"../Images/IMG_0426.JPEG\"\n\nfunction ImageSection() {\n    return (\n        <div className=\"ImageSection\">\n            <div className=\"image-content\">\n                <div className=\"about-info\">\n                    <p className=\"about-text\">\n                        <span>I am a software engineer at Amazon and a former graduate of Cornell & RIT CS.</span>\n                        <br/><br/>\n                        In my current job, I work on large scale software systems with an emphasis on spark ETL jobs and ML ops.\n                        I have a background in ML from my masters as well as from my previous role and internship.\n                        <br/><br/>\n                        Outside of work I like to spend my time on my project, Entropy Audio, which aims to redefine how we create sound for music composition.\n                        I also love trying new food, cool architecture, and keeping up with the latest trends in ML and ML systems.\n                    </p>\n                </div>\n                <div className=\"about-img-wrapper\">\n                    <img\n                        src={profilePic}\n                        alt=\"Benjamin Jordan headshot\"\n                        className=\"about-img\"\n                    />\n                </div>\n            </div>\n            {/*<a className=\"download-link\" style={{color: \"var(--font-color2)\"}} href={resume} download>*/}\n            {/*    <button className=\"btn\">Download CV</button>*/}\n            {/*</a>*/}\n        </div>\n    )\n}\n\nexport default ImageSection;\n","import React from 'react';\nimport Title from \"../Components/Title\";\nimport Skills from \"../Components/Skills\";\nimport ImageSection from \"../Components/ImageSection\";\nimport resume from \"../Downloads/Benjamin_Jordan_Resume_2025.pdf\";\n\nfunction AboutPage() {\n    return (\n        <div className=\"AboutPage\">\n            <Title title={'Ben Jordan'} progress={25}/>\n            <ImageSection />\n            <Title title={'CV'} progress={50}/>\n            <a className=\"download-link\" style={{color: \"var(--font-color2)\"}} href={resume} download>\n                <button className=\"btn\">Download</button>\n            </a>\n        </div>\n    );\n}\n\nexport default AboutPage;\n","import React, {useEffect} from 'react';\nimport {FontAwesomeIcon} from \"@fortawesome/react-fontawesome\";\nimport {useState} from 'react'\nimport ReactAudioPlayer from 'react-audio-player';\n\n\nfunction MenuItem({menuItem, id, setId}) {\n    const linkify = (text) => {\n        if (!text) return '';\n        // If manual anchors are present, leave text unchanged\n        if (/<a\\b[^>]*>/i.test(text)) return text;\n        // Linkify bare URLs while avoiding attribute contexts and quotes\n        return text.replace(/(^|[^\"'==])(https?:\\/\\/[^\\s<)\"']+)/g, (match, prefix, rawUrl) => {\n            const url = rawUrl.replace(/[.,!?)]*$/, '');\n            const trailing = rawUrl.slice(url.length);\n            return `${prefix}<a href=\"${url}\" target=\"_blank\" rel=\"noopener noreferrer\">${url}</a>${trailing}`;\n        });\n    };\n    const [expanded, setExpanded] = useState(true);\n    return (\n        <div className={`MenuItem`}>\n            {\n                menuItem.map((item) =>\n                {\n                    return <div className={`portfolio`} key={item.id}>\n                        <h5>\n                            {/*{!item.link ? \"\" : <a target = \"_blank\" href={item.link}>*/}\n                            {/*    <FontAwesomeIcon icon={item.icon} className='icon'/>*/}\n                            {/*</a>}*/}\n                            <div className=\"title\">\n                                {item.title}\n                            </div>\n                        </h5>\n\n                        <div style={{maxHeight: `${expanded && (id === -1 || item.id === id) ? \"400vh\" : \"24vh\"}`}} className={`project-content`}>\n                            <div className={`${expanded && (id === -1 || item.id === id)? 'text-cover-plain' : 'text-cover'}`}></div>\n                            {/*<button className=\"expand-btn\" onClick={() => {*/}\n                            {/*    if(!expanded)*/}\n                            {/*    {*/}\n                            {/*        setId(item.id);*/}\n                            {/*        setExpanded(true);*/}\n                            {/*    }*/}\n                            {/*    else*/}\n                            {/*    {*/}\n                            {/*        setId(-1);*/}\n                            {/*        setExpanded(false);*/}\n                            {/*    }*/}\n                            {/*}}>Expand</button>*/}\n                            <div className=\"flex-container\">\n                                <p className=\"description\" dangerouslySetInnerHTML={{\n                                    __html: linkify(item.descriptions ? (item.descriptions[0] || \"\") : \"\")\n                                }} />\n                                {(() => {\n                                        if (item.images && item.images[0]) {\n                                            return <div>\n                                                <img className=\"img\"\n                                                     src={item.images[0]}\n                                                     alt=\"\"/>\n                                                <div\n                                                    className=\"img-caption\">{item.imagecap[0]}</div>\n                                            </div>\n                                        }\n                                    }\n                                )()}\n                                <p className=\"description\" dangerouslySetInnerHTML={{\n                                    __html: linkify(item.descriptions ? (item.descriptions[1] || \"\") : \"\")\n                                }} />\n                                {/*{(() => {*/}\n                                {/*    if (item.audio && item.audiocap) {*/}\n                                {/*        return <div className=\"audio-container\">*/}\n                                {/*            <div>*/}\n                                {/*                <ReactAudioPlayer className=\"audio-player\"*/}\n                                {/*                                  src={item.audio[0]}*/}\n                                {/*                                  controls*/}\n                                {/*                />*/}\n                                {/*                <div className=\"audio-caption\">{item.audiocap[0]}</div>*/}\n                                {/*            </div>*/}\n                                {/*            <div>*/}\n                                {/*                <ReactAudioPlayer className=\"audio-player\"*/}\n                                {/*                                  src={item.audio[1]}*/}\n                                {/*                                  controls*/}\n                                {/*                />*/}\n                                {/*                <div className=\"audio-caption\">{item.audiocap[1]}</div>*/}\n                                {/*            </div>*/}\n                                {/*        </div>*/}\n                                {/*    }*/}\n                                {/*})()}*/}\n                                <p className=\"description\" dangerouslySetInnerHTML={{\n                                    __html: linkify(item.descriptions ? (item.descriptions[2] || \"\") : \"\")\n                                }} />\n                                {(() => {\n                                        if (item.images && item.images[1]) {\n                                            return <div>\n                                                <img className=\"img\"\n                                                     src={item.images[1]}\n                                                     alt=\"\"/>\n                                                <div className=\"img-caption\">{item.imagecap[1]}</div>\n                                            </div>\n                                        }\n                                    }\n                                )()}\n                                <p className=\"description\" dangerouslySetInnerHTML={{\n                                    __html: linkify(item.descriptions ? (item.descriptions[3] || \"\") : \"\")\n                                }} />\n\n                                <p className=\"description\" dangerouslySetInnerHTML={{\n                                    __html: linkify(item.descriptions ? (item.descriptions[4] || \"\") : \"\")\n                                }} />\n                                <p className=\"description\" dangerouslySetInnerHTML={{\n                                    __html: linkify(item.descriptions ? (item.descriptions[5] || \"\") : \"\")\n                                }} />\n                                <p className=\"description\" dangerouslySetInnerHTML={{\n                                    __html: linkify(item.descriptions ? (item.descriptions[6] || \"\") : \"\")\n                                }} />\n                                {(() => {\n                                        if (item.images && item.images[2]) {\n                                            return <div>\n                                                <img className=\"img\"\n                                                     src={item.images[2]}\n                                                     alt=\"\"/>\n                                                <div className=\"img-caption\">{item.imagecap[2]}</div>\n                                            </div>\n                                        }\n                                    }\n                                )()}\n                                {(() => {\n                                        if (item.images && item.images[3]) {\n                                            return <div>\n                                                <img className=\"img\"\n                                                     src={item.images[3]}\n                                                     alt=\"\"/>\n                                                <div className=\"img-caption\">{item.imagecap[3]}</div>\n                                            </div>\n                                        }\n                                    }\n                                )()}\n                            </div>\n                        </div>\n                    </div>\n                })\n            }\n        </div>\n    );\n}\n\nexport default MenuItem;\n","export default __webpack_public_path__ + \"static/media/audiocraft1.7119c8f1.png\";","export default __webpack_public_path__ + \"static/media/dslabs1.d3e62336.PNG\";","export default __webpack_public_path__ + \"static/media/dslabs2.37fb7c6f.png\";","export default __webpack_public_path__ + \"static/media/SynthLM3.828823aa.PNG\";","export default __webpack_public_path__ + \"static/media/SynthLM4.a3f325ba.PNG\";","export default __webpack_public_path__ + \"static/media/SAE1.ee662d30.PNG\";","export default __webpack_public_path__ + \"static/media/SAE2.2881e408.PNG\";","export default __webpack_public_path__ + \"static/media/SAE4.5677207e.PNG\";","export default __webpack_public_path__ + \"static/media/ITP1.c2d554f0.PNG\";","export default __webpack_public_path__ + \"static/media/ITP2.7500f3b1.PNG\";","export default __webpack_public_path__ + \"static/media/ITP3.e9118fa3.PNG\";","export default __webpack_public_path__ + \"static/media/ITP4.bc1ecae6.PNG\";","export default __webpack_public_path__ + \"static/media/GNN1.93a9ac99.PNG\";","export default __webpack_public_path__ + \"static/media/GNN2.d55ebba0.png\";","export default __webpack_public_path__ + \"static/media/EQ2.4f946a9f.PNG\";","export default __webpack_public_path__ + \"static/media/OMNI1.1c3f5bba.PNG\";","export default __webpack_public_path__ + \"static/media/OMNI2.d23d7b6b.PNG\";","export default __webpack_public_path__ + \"static/media/OMNI4.1e9f70eb.PNG\";","export default __webpack_public_path__ + \"static/media/FV3.8dd5368a.PNG\";","export default __webpack_public_path__ + \"static/media/layer2_feat2.d8481bae.png\";","export default __webpack_public_path__ + \"static/media/FV5.f9dd787d.png\";","export default __webpack_public_path__ + \"static/media/clarinet-dry.7f32045e.mp3\";","export default __webpack_public_path__ + \"static/media/clarinet-wet.0e96b129.mp3\";","export default __webpack_public_path__ + \"static/media/clarinet-wet2.77a5b03a.mp3\";","export default __webpack_public_path__ + \"static/media/eq-dry.d1d955e3.mp3\";","export default __webpack_public_path__ + \"static/media/eq-wet.9ed82bf8.mp3\";","export default __webpack_public_path__ + \"static/media/dit.748b4c71.png\";","export default __webpack_public_path__ + \"static/media/frontend.920c5237.PNG\";","export default __webpack_public_path__ + \"static/media/IMG_8809.033bb5d6.JPEG\";","const descriptions =\n    {\n        synthlm1: \"Given the impressive modeling capabilities of modern diffusion and flow-based models in the speech and music domains, \" +\n            \"it seems clear to me that there will be some form of natural langauge tool available for music composers in the future. \" +\n            \"Unfortunately, audio generation models are not suitable for music composition in their current state. \" +\n            \"Some of these models may be able to generate full songs, but none are able to generate high-quality, individual samples well. \" +\n            \"This fact highlights both a large data bottleneck as well as a lack of focus on this task by the community.\",\n\n        synthlm2: \"The open source model that first peaked my interest was MusicGen from Meta AI in 2023. This is an \" +\n            \"autoregressive transformer model that aims to predict time-steps in a discretized, compressed audio sequence conditioned on text. \" +\n            \"Although these models were a huge step up in open source at the time and implement an interesting approach to audio modeling, \" +\n            \"the limitations of autoregressive models become apparent when playing around with the model (consistency issues and slow generative speeds for long sequences). \" +\n            \"This doesn't mean autoregressive models are inherently bad, I just think that maybe they are the best fit for the audio generation task. \" +\n            \"Some other issues like artifact-free latent audio encoding and decoding were not completely solved at this point, lowering the quality of the model further. \" +\n            \"Encodec (the model used in AudioGen) is solid, but not yet at the level needed for professional audio.\",\n\n        synthlm3: \"By the end of the year (Dec 2023), I began experimenting with finetuning MusicGen with somewhat limited results. \" +\n            \"Through testing I determined that the autoencoder Descript Audio Codec (DAC) had superior audio quality so I swapped out Encodec with DAC for these experiments. \" +\n            \"Although DAC was an improvement on Encodec, I was still experiencing issues with model efficiency (AudioGen is a 7B model), dataset quality and breadth, and sequence consistency. \" +\n            \"In June 2024, StabilityAI released Stable Audio Open (SAO). SAO is a 1B diffusion model that operates on a continuous latent space provided by a newer encoder model called Oobleck. \" +\n            \"To me, SAO is superior to AudioGen in consistency, quality, simplicity, and efficiency. Diffusion/flow models are the clear winner for audio generation.\",\n\n        synthlm4: \"However, the data bottleneck for this task still remains. \" +\n            \"To fix this, I have been working on a dataset that is currently sitting at around 2TB. \" +\n            \"The largest portion of this data came from a program I made to automate the data gathering and labeling process. I used LLMs \" +\n            \"Gemini 2.5 Flash (API) and Qwen3-30B (Local) to generate captions given metadata of an audio sample. Each datapoint has metadata and conditioning fields \" +\n            \"prepared in a predefined schema and saved as a json file. This dataset format was inspired by the dataset classes in \" +\n            \"<a href='https://github.com/facebookresearch/audiocraft' target='_blank' rel='noopener noreferrer'>Meta's AudioCraft codebase</a>. \" +\n            \"The rest of the data is either open source or manually labeled. When I get a chane, I am hoping to finetune a multimodal LLM to do labelling from raw audio as well. \" +\n            \"This is pending completion of the metadata-caption dataset, so I have lots of training data to play around with. I used <a href='https://huggingface.co/docs/transformers/model_doc/clap' target='_blank' rel='noopener noreferrer'>CLAP score</a> to filter all open source and synthetic data to ensure that data is high quality.\",\n\n        synthlm5: \"On the engineering side, I created 4 main code packages: entropy_training, entropy_models, entropy_metrics, and entropy_data. \" +\n            \"The model package was initialized from the model code in the <a href='https://github.com/Stability-AI/stable-audio-tools' target='_blank' rel='noopener noreferrer'>Stable Audio Tools</a> repo \" +\n            \"(which surprisingly contained more bugs than I would have liked! A good lesson in testing your code and reviewing open source I guess) \" +\n            \"and contains code for the DiT, autoencoder, and conditioning module. For text embeddings, I swapped out the original T5 used with SAO and added in \" +\n            \"Qwen3 Embedding, CLIP, and CLAP for diverse text features. The data package holds the code for the audio dataset as well as \" +\n            \"code for curating synthetic data and analyzing the dataset distribution. The training package contains controller/orchestrator code for training and evaluating the model, \" +\n            \"and the metrics package has metrics for evaluation. Some interesting metrics I have been using are the model scores from <a href='https://ai.meta.com/research/publications/meta-audiobox-aesthetics-unified-automatic-quality-assessment-for-speech-music-and-sound/' target='_blank' rel='noopener noreferrer'>Meta's Audiobox Aesthetics</a>. \" +\n            \"This is a pretrained model that predicts scores for an audio's content enjoyment, content quality, production complexity, and production quality. \" +\n            \"These scores have actually been decent indicators of training progress and could potentially be useful for some experimental RL post-training. I also used CLAP score and personal judgement for evaluations.\",\n\n        synthlm6: \"Initial/experimental training runs for the diffusion model were done on my local workstation with 1x5090. When I'm ready to scale \" +\n            \"I will probably move to a multi-gpu setup on RunPod (and use up some free startup credits I have there). To speed up training, I used PyTorch's automatic mixed precision \" +\n            \"to convert the original float32 SAO weights down to bfloat16. Bfloat16 was prefered over float16 as it is just a simple precision/mantissa truncation and no re-scaling is required. \" +\n            \"I also preencoded the audio latents ahead of time in my dataset as the CNN was a bottleneck during the training step. For training/experiment tracking I used wandb.\",\n\n\n        synthlm7: \"I created a <a href='https://github.com/EntropyAudio/entropy_frontend' target='_blank' rel='noopener noreferrer'>frontend with Angular</a> \" +\n            \"as well as a small serverless backend + model inference function. For those backend pieces I used AWS Lambdas+S3+DDB and RunPod Serverless Endpoints respectively. My goal with the frontend was to make something \" +\n            \"that felt like a hybrid between digital synth and LLM UIs, and also to make a UI that allows for natural preference data selection (aka a data flywheel). \" +\n            \"RunPod/Lambda code can be found here: Note that the core packages like entropy_training are private.\",\n\n\n\n\n\n\n\n\n\n        // dslabs1: \"DSLabs was a semester long project that I completed while taking Cornell's CS5414 \" +\n        //     \"(Distributed Computing) with Lorenzo Alvisi. This class was easily one of the most challenging, rewarding, \" +\n        //     \"and well designed courses I have ever taken. The project itself consisted of a framework that allows \" +\n        //     \"students to create and test distributed systems, along with four major labs where we were tasked with \" +\n        //     \"implementing a system similar in functionality to Google's Spanner.\",\n        // dslabs2: \"Lab 1 involved implementing an \\\"at-most-once\\\" key-value store (duplicate commands will only execute once, results are cached), along\" +\n        //     \" with a basic client and server. Lab 2 consisted of adding primary-backup replication to\" +\n        //     \" lab 1 using an all-knowing view service server that decides on primary backup configurations. This allows for state replication and consistency, \" +\n        //     \"but it also leaves us with a single point of failure (the view service).\",\n        // dslabs3: \"Lab 3 fixes this problem using Paxos. Paxos \" +\n        //     \"is an intriguing algorithm that allows a group of servers to be fault tolerant as long as a majority of servers in the group don't fail. It \" +\n        //     \"also guarantees that consensus can be reached during periods of synchrony. This part involved a bit too many hours \" +\n        //     \"of grinding in order to debug the system, but I'm proud to say that we passed all of the test cases.\",\n        // dslabs4: \"Lab 4 added on multi-key transactions and sharding. This allows the system to process operations \" +\n        //     \"in parallel thus increasing performance proportional to the number of server groups. We also had to implement two\" +\n        //     \" phase commit for agreement between server groups during transactions. On its own 2PC is susceptible to failures, \" +\n        //     \"but when paired with paxos provides agreement without any major availability issues.\",\n        //\n        // sae1: \"After working for Professor Kim in 2020, I was rehired as a part-\" +\n        //     \"time developer during my last semester of undergrad. During this semester, my task was to write a program \" +\n        //     \"that would allow Dr. Kim to collect data on how listeners interpret the spatial characteristics of audio. \" +\n        //     \"This was quite an enjoyable project because I was given a general overview of what to build, but every \" +\n        //     \"aspect of design and implementation was left up to me.\",\n        // sae2: \"The main feature of this program is an interactive 3D visual that is supposed to represent audio and its spacial \" +\n        //     \"characteristics. Users hear a series of songs, and then adjust a set of four attribute sliders \" +\n        //     \"(width, depth, immersion, and clarity) to morph the 3D visual until it best describes each song.\",\n        // sae3: \"Given that this project was a website, I decided to use Angular to get some more \" +\n        //     \"experience with it. I really like Angular + Typescript because of the OOP style, and because it helps me keep my \" +\n        //     \"projects organized. As for the 3D visual, I used a library called three.js. This was \" +\n        //     \"easily the most challenging part of the project since it was my first time doing anything related to \" +\n        //     \"graphics, but I learned a lot! I created a custom shader that morphs based on the music's volume and attribute slider values. \",\n        // sae4: \"For the design of the software, I added UI components such as the attribute sliders and menus, \" +\n        //     \"a view component to hold the three.js canvas, a singular audio service that controls everything sound related \" +\n        //     \"and can be injected into any component, and a singular session values service used to maintain \" +\n        //     \"important values during each instance of the program (such as the current round number or username). \" +\n        //     \"This service was injected into the slider components and the view component, so both the sliders and the 3D graphic could \" +\n        //     \"have realtime access to the attribute sliders' values.\",\n        //\n        // ipt1: \"This was one of two projects created during my internship with Professor Sungyoung Kim at RIT. In collaboration with \" +\n        //     \"a team from University of Iowa, \" +\n        //     \"we attempted to evaluate the effectiveness of hearing devices called hybrid cochlear implants. \" +\n        //     \"The team was also interested in people's ability to understand speech depending on background noise level. \" +\n        //     \"I was given the task of independently creating a website that would allow the researchers to test participants hearing abilities \" +\n        //     \"and collect data. This ended up being a great opportunity because it was the largest project I had ever\" +\n        //     \" worked on, I got to learn about web development, and the team successfully published research using the data\" +\n        //     \" collected with the software. It's a good feeling when the software you make is used for something important.\",\n        // ipt2:\"The website contains 5 unique testing modules. The Inharmonicity Training and Speech-In-Noise tests have \" +\n        //     \"2 and 3 different modes respectively. All tests heavily rely on the Javascript Web Audio API to generate \" +\n        //     \"and process sound at various frequencies and levels. The website is connected to a backend SQL database to \" +\n        //     \"store data for each user.\",\n        // ipt3:\"The main focus of the program was the Inharmonicity Training. In this module, users are presented with a \" +\n        //     \"box that produces a tone as their mouse hovers over it. The tone changes depending on the location of the\" +\n        //     \" mouse within the box. This tone consists of a group of low frequency oscillators and a group of \" +\n        //     \"high frequency oscillators set with precise frequency ratios. The goal is for the user to move their mouse \" +\n        //     \"inside the box until the tone sounds most \\\"harmonic\\\". After selecting a point, a gradient appears on the \" +\n        //     \"box that shows the user how correct their guess was. This gradient is calculated based on final mouse \" +\n        //     \"position and the randomized frequency ranges of the box's x and y axes set before each trial.\",\n        // ipt4: \"As part of a separate research question, I also added a speech-in-noise test that played a series \" +\n        //     \"of words alongside background noise. The user just has to guess which word was spoken.\",\n        //\n        // gnn1:\"For the final research project in my machine learning course at RIT, we were tasked with researching a deep learning \" +\n        //     \"architecture that we didn't cover in class, proposing an experiment, and then putting together a \" +\n        //     \"final paper and presentation. After doing some searching online, I decided to do my project on \" +\n        //     \"graph neural networks (specifically the GraphSAGE architecture).\",\n        // gnn2:\"The GraphSAGE algorithm works by first randomly sampling neighboring nodes of a given node in a graph, \" +\n        //     \"and then combining the original and sampled node's embeddings using an aggregation function. It's best to think of this \" +\n        //     \"as a generalization of convolution for graph data. \" +\n        //     \"Its also similar to the idea of summarizing word embeddings into sentence embeddings in NLP.\",\n        // gnn3:\"For the experiment portion of the project, I proposed that if we methodically select which aggregation function \" +\n        //     \"is used for each layer, then we will get better results out of our model \" +\n        //     \"(most GNNs use a single type of aggregation function for all layers). This is because some aggregators,\" +\n        //     \" such as mean pooling, may be better at summarizing earlier layers of \" +\n        //     \"embeddings than max pooling for example. To test this idea out, \" +\n        //     \"I used the CORA dataset (basically MNIST digits for GNNs) along with a PyTorch implementation of GraphSAGE. \" +\n        //     \"I implemented max and mean aggregators to go along with model.\",\n        // gnn4: \"The results showed that the proposed combination of aggregation layers (mean in earlier layers, and max in later layers) \" +\n        //     \"did in fact result in an increase in F1 score. However, this experiment was at such a small scale that testing on a larger \" +\n        //         \"dataset and model would need to be done to make any conclusions.\",\n        // gnn5: \"Overall, this turned out to be a great choice for my project. \" +\n        //     \"I was in the process of finishing up a graph theory course, \" +\n        //     \"so graphs concepts were fresh in my mind. It was also cool to study GNNs given that they \" +\n        //     \"aren't discussed nearly as much as other modalities of deep learning. Lastly, it was a good experience \" +\n        //     \"to learn a little more about writing a project proposal and creating an experiment.\" +\n        //     \" Although it was challenging doing a research project on a new topic in a little over a month, \" +\n        //     \"I'm glad I went through it.\",\n        //\n        // eq1: \"As an avid user of music production software, I always wondered how the tools I was using were created. \" +\n        //     \"I also wanted to brush up on my C++ skills. Therefore, \" +\n        //     \"to kill two birds with one stone I decided to dive in and make a parametric EQ (a common audio mixing effect).\",\n        // eq2: \"At first, I looked into writing VST3s (the standard format of an audio plugin) from scratch. However, it became \" +\n        //     \"apparent that this wasn't a simple feat for someone starting out. I ended up using an excellent C++ \" +\n        //     \"framework called JUCE that includes libraries for both audio processing and UI elements.\",\n        // eq3: \"My final EQ consisted of 2 notch filters for middle frequencies, a low pass filter to cut high frequencies, \" +\n        //     \"and a high pass filter to cut low frequencies. Each filter has a small bypass button above it. \" +\n        //     \"Writing the program involved routing audio input \" +\n        //     \"through the four filters, and connecting the UI knobs to the filter parameters. \" +\n        //     \"I also created a real-time frequency analyzer that sits behind a visualization of the EQ curve (the orange line). \" +\n        //     \"Lastly, I edited the algorithm for one of the built in JUCE filters to allow the user \" +\n        //     \"to select different slope values for the high and low pass filters.\",\n        // eq4: \"Although its not the worlds flashiest audio plugin, I am very satisfied that I got it working inside \" +\n        //     \"my own music production software. Now that I have more experience behind my belt, I can hopefully tackle more \" +\n        //     \"interesting ideas that I have.\",\n        //\n        // omni1: \"Alongside the cochlear implant testing software I created while interning with Professor Kim, I was also given \" +\n        //     \"the task of fleshing out another VR/AR project idea in my free time. This project was created \" +\n        //     \"in an attempt to preserve the aural characteristics of historical buildings.\",\n        // omni2: \"The software is designed to take in a dry audio sample (no reverb), and play it back as if it was \" +\n        //     \"inside a room, from any position in the room. The final result ended up working surprisingly well! \" +\n        //     \"The way something like this is done is by recording impulses, which are essentially isolated reverb \" +\n        //     \"tails, inside a room using an ambisonic 4 channel microphone. Then you convolve the \" +\n        //     \"source file with those impulse recordings, and combine the resulting 4 audio files in such a way such that they create \" +\n        //     \"B format ambisonic files.\",\n        // omni3: \"These B format files can then be converted to stereo using a javascript library called Omnitone. \" +\n        //     \"In the program, users can rotate their position in the room using the VR viewer. Users \" +\n        //     \"can also select different sound source and listening locations, and change which microphone is being used \" +\n        //     \"with the control panel on the bottom.\",\n        //\n        // fv1: \"This is a small program that came about as I was working on a project for my internship. I was looking \" +\n        //     \"into how interpretable one could make CNNs, and I came across a Stanford YouTube lecture on \" +\n        //     \"visualization for computer vision. One of the topics briefly discussed in the lecture was called gradient ascent, \" +\n        //     \"which is originally from the paper 'Understanding Neural Networks Through Deep Visualization'.\",\n        // fv2: \"A more common idea that is similar is saliency maps. Saliency maps are created by inputting an \" +\n        //     \"image into a network, and visualizing which pixels are most responsible for the prediction made. \" +\n        //     \"On the other hand, Gradient ascent aims to generate a new image that maximally activates a given output feature or class. \" +\n        //     \"The paper mentioned above discusses this technique, and also talks about how to make the results of gradient ascent into more interpretable, natural looking images.\",\n        // fv3: \"I tried implementing this algorithm myself using PyTorch, and after a little bit of fooling \" +\n        //     \"around with hyperparameters, I was able to get some cool images! I did it by taking a pre-trained PyTorch ResNet50 (trained on ImageNet1K), \" +\n        //     \"creating a blank image and passing it to the optimizer, and then performing gradient ascent on the image pixels until the image exactly maximized \" +\n        //     \"a specified class in the model. Following the advice of the paper, I also added gaussian blurring, L2 regularization, and gradient \" +\n        //     \"clipping which helped make the images much cleaner once I found the right settings. I also made it so the images could be created in parallel/batches. \" +\n        //     \"This way, one could potentially generate separate images for all output features in a given layer in one run.\",\n        // fv4: \"I ended up seeing some very interesting things during my testing. First, this technique does not appear to work \" +\n        //     \"with transformers. The resulting images look like a bunch of small squares with random patterns \" +\n        //     \"stitched together. This is presumably due to the way images are chopped up before being fed into a transformer. \" +\n        //     \"I also found it to be really cool how the visualizations that showed up in my images had different \" +\n        //     \"locations, shapes, and sizes depending on hyperparameters and image initialization. However, they still maintained \" +\n        //     \"the general characteristics of the feature/class that they represented. I think this is a great example \" +\n        //     \"of how CNNs can pick out specific features of an image regardless of location or other factors like size.\",\n        //\n        // portfolio1: \"This Website! During quarantine I wanted to give React a try, so I started with a tutorial I found online and \" +\n        //     \"made some edits. I recently did a re-design of the projects page as well.\",\n        //\n        // temp: \"Content coming soon...\"\n\n\n    };\nexport default descriptions\n","import dslabs1 from \"../Images/dslabs1.PNG\";\nimport dslabs2 from \"../Images/dslabs2.png\";\nimport SynthLM3 from '../Images/SynthLM3.PNG';\nimport SynthLM4 from '../Images/SynthLM4.PNG';\nimport SAE1 from \"../Images/SAE1.PNG\";\nimport SAE2 from \"../Images/SAE2.PNG\";\nimport SAE4 from \"../Images/SAE4.PNG\";\nimport ITP1 from \"../Images/ITP1.PNG\";\nimport ITP2 from \"../Images/ITP2.PNG\";\nimport ITP3 from \"../Images/ITP3.PNG\";\nimport ITP4 from \"../Images/ITP4.PNG\";\nimport GNN1 from \"../Images/GNN1.PNG\";\nimport GNN2 from \"../Images/GNN2.png\";\nimport EQ2 from \"../Images/EQ2.PNG\";\nimport OMNI1 from \"../Images/OMNI1.PNG\";\nimport OMNI2 from \"../Images/OMNI2.PNG\";\nimport OMNI4 from \"../Images/OMNI4.PNG\";\nimport FV1 from \"../Images/FV3.PNG\";\nimport FV2 from \"../Images/layer2_feat2.png\";\nimport FV3 from \"../Images/FV5.png\";\n\nimport dry from \"../Images/clarinet-dry.mp3\"\nimport wet from \"../Images/clarinet-wet.mp3\"\nimport wet2 from \"../Images/clarinet-wet2.mp3\"\nimport eqdry from \"../Images/eq-dry.mp3\"\nimport eqwet from \"../Images/eq-wet.mp3\"\nimport audiocraft1 from \"../Images/audiocraft1.png\"\nimport audiocraft2 from \"../Images/frontend.PNG\"\nimport dit from \"../Images/dit.png\"\nimport pc from \"../Images/IMG_8809.JPEG\"\n\nimport descriptions from \"./ProjectDescriptions\"\n\nimport {faGithub} from \"@fortawesome/free-brands-svg-icons\";\nimport {faYoutube} from \"@fortawesome/free-brands-svg-icons\";\nimport {faSoundcloud} from \"@fortawesome/free-brands-svg-icons\";\nimport {faChrome} from \"@fortawesome/free-brands-svg-icons\";\nconst portfolios = [\n    {\n        id: 1,\n        category: ['2023'],\n        link: 'https://entropyaudio.io/',\n        icon: faChrome,\n        descriptions: [descriptions.synthlm1, descriptions.synthlm2, descriptions.synthlm3, descriptions.synthlm4\n        , descriptions.synthlm5, descriptions.synthlm6, descriptions.synthlm7],\n        title: 'Generative, Transformer-Based Models For Music Composition',\n        images: [audiocraft1, dit, pc],\n        imagecap: [\"1. MusicGen + Encodec Architecture\", \"2. Diffusion Transformer (DiT) Paper\", \"3. My Local Machine\"]\n    },\n    // {\n    //     id: 2,\n    //     category: ['2023'],\n    //     link: 'https://github.com/emichael/dslabs',\n    //     icon: faGithub,\n    //     descriptions: [descriptions.dslabs1, descriptions.dslabs2, descriptions.dslabs3, descriptions.dslabs4],\n    //     images: [dslabs1, dslabs2],\n    //     imagecap: [\"1: The Part-Time Parliament\", \"2: The greatest moment of my life\"],\n    //     title: 'DSLabs - Sharded Key-Value Store'\n    // },\n    // {\n    //     id: 10,\n    //     category: ['2023'],\n    //     descriptions: [descriptions.fv1, descriptions.fv2, descriptions.fv3, descriptions.fv4, descriptions.fv5],\n    //     title: 'FeatureViz - Deep Learning Visualization',\n    //     link:\"https://github.com/Bej9038/FeatureViz\",\n    //     icon: faGithub,\n    //     images: [FV1, FV2, FV3],\n    //     imagecap: [\"1: A cool looking feature from the third group of layers in ResNet50\",\n    //         \"2: A more basic feature from an earlier layer\",\n    //         \"3: A faint visualization of the stingray class from the final classifier\"],\n    // },\n    // {\n    //     id: 7,\n    //     category: ['2021'],\n    //     link: 'https://github.com/Bej9038/EQ',\n    //     icon: faGithub,\n    //     descriptions: [descriptions.eq1, descriptions.eq2, descriptions.eq3, descriptions.eq4],\n    //     audio: [eqdry, eqwet],\n    //     audiocap:[\"A drum loop with the EQ bypassed\", \"The same drum loop after applying the EQ curve shown in the image above\"],\n    //     images: [EQ2],\n    //     imagecap: [\"1: The EQ in action in my music production software\"],\n    //     title: 'EQ Audio Plugin'\n    // },\n    // {\n    //     id: 4,\n    //     category: ['2020'],\n    //     link: 'https://github.com/Bej9038/ImplantTestingProgram',\n    //     icon: faGithub,\n    //     descriptions: [descriptions.ipt1, descriptions.ipt2, descriptions.ipt3, descriptions.ipt4],\n    //     images: [ITP1, ITP3, ITP4, ITP2],\n    //     imagecap: [\"1: The main menu\", \"2: Inharmonicty training\",\n    //         \"3: Setting the frequency ranges on the canvas's axes and creating the oscillators\", \"4: Speech to noise ratio selection\"],\n    //     title: 'Implant Testing Program'\n    // },\n    // {\n    //     id: 3,\n    //     category: ['2022'],\n    //     link: 'https://github.com/Bej9038/SpatialAttributeEvaluation',\n    //     icon: faGithub,\n    //     descriptions: [descriptions.sae1, descriptions.sae2, descriptions.sae3, descriptions.sae4],\n    //     images: [SAE4, SAE1, SAE2],\n    //     imagecap: [\"1: Part of the initial project specifications\", \"2: Welcome menu\",\"3: Playing around with the controls\"],\n    //     title: 'Spatial Attributes Evaluation'\n    // },\n    // {\n    //     id: 8,\n    //     category: ['2020'],\n    //     link: 'https://github.com/Bej9038/OmnitoneV2',\n    //     icon: faGithub,\n    //     descriptions: [descriptions.omni1, descriptions.omni2, descriptions.omni3],\n    //     audio: [dry, wet, wet2],\n    //     audiocap:[\"The original audio file\", \"The audio file being played inside the simulated savings bank\"],\n    //     images: [OMNI1, OMNI2, OMNI4],\n    //     imagecap: [\"1: The Omnitone interface displaying the Rochester savings bank. \" +\n    //     \"Users can use their mouse to explore the VR room and its audio characteristics.\",\n    //         \"2: The second selectable room\"],\n    //     title: 'Omnitone'\n    // },\n    // {\n    //     id: 5,\n    //     category: ['2022'],\n    //     link: 'https://github.com/Bej9038/GraphSAGE-ML-Project',\n    //     icon: faGithub,\n    //     descriptions: [descriptions.gnn1, descriptions.gnn2, descriptions.gnn3, descriptions.gnn4, descriptions.gnn5],\n    //     images: [GNN2, GNN1],\n    //     imagecap: [\n    //         \"1: A GraphSAGE layer visualized\",\n    //         \"2: Visualization of the CORA dataset. It consists of 2708 scientific publications classified \" +\n    //     \"into one of seven classes. The citation network consists of 5429 directed links between papers.\",\n    //         ],\n    //     title: 'Graph Neural Network Research Project'\n    // },\n    // {\n    //     id: 6,\n    //     category: ['2021'],\n    //     link: 'https://github.com/Bej9038/PortfolioWebsite',\n    //     icon: faGithub,\n    //     descriptions: [descriptions.portfolio1],\n    //     title: 'Portfolio Website'\n    // },\n    // {\n    //     id: 9,\n    //     category: ['2022'],\n    //     link: 'https://github.com/Bej9038/OmnitoneV2',\n    //     icon: faGithub,\n    //     // image: port2,\n    //     title: 'Encrypted Messenger'\n    // },\n]\n\nexport default portfolios;\n","import React from 'react';\nimport Title from \"../Components/Title\";\nimport Categories from \"../Components/Categories\";\nimport MenuItem from \"../Components/MenuItem\";\nimport portfolios from \"../Components/ProjectList\"\nimport {useState} from 'react'\n\nfunction onlyUnique(value, index, array) {\n    return array.indexOf(value) === index;\n}\nlet cats = []\nportfolios.map(item => item.category.map(i => cats.push(i)))\nlet allCategories = ['All', ...cats.filter(onlyUnique)]\nfunction ProjectsPage() {\n    const [categories, setCategories] = useState(allCategories);\n    const [menuItems, setMenuItems] = useState(portfolios);\n    const [id, setId] = useState(-1);\n\n    const filter = (category) =>\n    {\n        if(category === 'All')\n        {\n            setMenuItems(portfolios);\n            return;\n        }\n        const filteredData= portfolios.filter((item)=>\n        {\n            return item.category.includes(category);\n        });\n        setMenuItems(filteredData);\n    }\n\n    return (\n        <div className=\"ProjectsPage\">\n            <div className=\"title\">\n                <Title title={'Entropy Audio'} progress={75}/>\n            </div>\n            <div className=\"portfolio-menu\">\n                {/*<Categories categories = {categories} filter={filter} />*/}\n                <MenuItem menuItem={menuItems} id={id} setId={setId}/>\n            </div>\n        </div>\n    );\n}\n\nexport default ProjectsPage;\n","import React from 'react';\nimport Title from \"../Components/Title\";\nimport { useForm, ValidationError } from '@formspree/react';\n\nfunction ContactPage() {\n    const [state, handleSubmit] = useForm(\"mqkwpwoa\");\n    if (state.succeeded) {\n        document.getElementsByClassName('success')[0].style.display = \"flex\";\n        document.getElementById('contact-form').reset();\n    }\n    return (\n        <div className=\"ContactPage\">\n            <div className=\"contact-title\">\n                <Title title={'Contact'} progress={100}/>\n            </div>\n            <div className=\"sections\">\n                <div className=\"context-info\">\n                    Phone: 607-339-1740\n                    <br/><br/>\n                    Email: bej9@cornell.edu, bejordae@amazon.com\n                    <br/><br/>\n                    Current Location: New York, NY\n                </div>\n                <div className=\"map-sect\">\n                    <iframe\n                        src=\"https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d193572.132814464!2d-74.11808698000894!3d40.705825455231026!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x89c24fa5d33f083b%3A0xc80b8f06e177fe62!2sNew%20York%2C%20NY!5e0!3m2!1sen!2sus!4v0000000000000!5m2!1sen!2sus\"\n                        width=\"600\"\n                        height=\"450\"\n                        style={{ border: 0 }}\n                        allowFullScreen=\"\"\n                        loading=\"lazy\"\n                        referrerPolicy=\"no-referrer-when-downgrade\"\n                    />\n            </div>\n\n            {/*<div className=\"contact-sect\">*/}\n            {/*    <form autoComplete=\"off\" onSubmit={handleSubmit} action=\"https://formspree.io/f/mqkwpwoa\" method=\"post\"*/}\n            {/*          id=\"contact-form\">*/}\n            {/*        <div className=\"form-group\">*/}\n            {/*            <label htmlFor=\"name\" className=\"label\">Name</label>*/}\n            {/*            <input autoComplete=\"new-password\" type=\"text\" id = \"name\" className=\"textio\" name = \"name\" />*/}\n            {/*            </div>*/}\n            {/*            <input type=\"hidden\" value = 'prayer'/>*/}\n\n            {/*            <div className=\"form-group\">*/}\n            {/*                <label htmlFor=\"email\" className=\"label\">Email</label>*/}\n            {/*                <input autoComplete=\"new-password\" type=\"text\" id=\"email\" className=\"textio\" name=\"email\"/>*/}\n            {/*            </div>*/}\n\n            {/*            <div className=\"form-group\">*/}\n            {/*                <label htmlFor=\"message\" className=\"label\">Message</label>*/}\n            {/*                <textarea id=\"message\" className=\"textio\" name=\"message\"/>*/}\n            {/*            </div>*/}\n            {/*            <button className='email-btn' type = \"submit\">Send</button>*/}\n            {/*        </form>*/}\n            {/*        <div className=\"success\">Massage Received!</div>*/}\n            {/*    </div>*/}\n            </div>\n        </div>\n    );\n}\n\nexport default ContactPage;\n","import { useEffect } from \"react\";\nimport { useLocation } from \"react-router-dom\";\n\nexport default function ScrollToTop() {\n    const { pathname } = useLocation();\n\n    useEffect(() => {\n        window.scrollTo(0, 0);\n    }, [pathname]);\n\n    return null;\n}\n","import './App.scss';\nimport './Styles/Layout.scss';\nimport './Styles/NavBar.scss';\nimport './Styles/HomePage.scss';\nimport './Styles/Title.scss';\nimport './Styles/Skills.scss';\nimport './Styles/AboutPage.scss';\nimport './Styles/ContactPage.scss';\nimport './Styles/ProjectsPage.scss';\nimport NavBar from './Components/NavBar';\nimport HomePage from './Pages/HomePage'\nimport AboutPage from './Pages/AboutPage';\nimport {Switch, Route, NavLink} from 'react-router-dom';\nimport ProjectsPage from \"./Pages/ProjectsPage\";\nimport ContactPage from \"./Pages/ContactPage\";\nimport React, {useState} from 'react'\nimport {FaArrowLeft, FaArrowRight} from 'react-icons/fa';\nimport ScrollToTop from \"./Components/ScrollToTop\";\n\nfunction App() {\n    const [navToggle, setNavToggle] = useState(false);\n    const navClick = () =>\n    {\n        if(window.innerWidth < 1000)\n        {\n            setNavToggle(!navToggle);\n        }\n    }\n\n  return (\n    <div className=\"App\">\n        <div className=\"nav-\">\n            <Switch>\n                <Route path=\"/\" exact>\n                    <NavLink className = \"rightarrow\" to=\"/Projects\" exact>\n                        <FaArrowRight />\n                        <FaArrowRight className = \"rightarrow2\"/>\n                    </NavLink>\n                </Route>\n\n                {/*<Route path=\"/About\" exact>*/}\n                {/*    <NavLink className = \"leftarrow\" to=\"/\" exact>*/}\n                {/*        <FaArrowLeft />*/}\n                {/*        <FaArrowLeft className = \"leftarrow2\"/>*/}\n                {/*    </NavLink>*/}\n                {/*    <NavLink className = \"rightarrow\" to=\"/Portfolio\" exact>*/}\n                {/*        <FaArrowRight />*/}\n                {/*        <FaArrowRight className = \"rightarrow2\"/>*/}\n                {/*    </NavLink>*/}\n                {/*</Route>*/}\n\n                <Route path=\"/Projects\" exact>\n                    <NavLink className = \"leftarrow\" to=\"/\" exact>\n                        <FaArrowLeft />\n                        <FaArrowLeft className = \"leftarrow2\"/>\n                    </NavLink>\n                    <NavLink className = \"rightarrow\" to=\"/Contact\" exact>\n                        <FaArrowRight />\n                        <FaArrowRight className = \"rightarrow2\"/>\n                    </NavLink>\n                </Route>\n\n                <Route path=\"/Contact\" exact>\n                    <NavLink className = \"leftarrow\" to=\"/Projects\" exact>\n                        <FaArrowLeft />\n                        <FaArrowLeft className = \"leftarrow2\"/>\n                    </NavLink>\n                </Route>\n\n            </Switch>\n        </div>\n\n\n\n      <div className={`sidebar ${navToggle ? 'nav-toggle': ''}`}>\n        <NavBar />\n      </div>\n      <div className=\"main-content\">\n        <div className=\"content\">\n            <Switch>\n                {/*<Route path=\"/\" exact>*/}\n                {/*    <ScrollToTop/>*/}\n                {/*    <HomePage />*/}\n                {/*</Route>*/}\n\n                <Route path=\"/\" exact>\n                    <ScrollToTop/>\n                    <AboutPage />\n                </Route>\n\n                <Route path=\"/Projects\" exact>\n                    <ScrollToTop/>\n                    <ProjectsPage />\n                </Route>\n\n                <Route path=\"/Contact\" exact>\n                    <ScrollToTop/>\n                    <ContactPage />\n                </Route>\n            </Switch>\n        </div>\n      </div>\n    </div>\n  );\n}\n\nexport default App;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport App from './App';\nimport {HashRouter} from \"react-router-dom\";\n\nReactDOM.render(\n  <React.StrictMode>\n    <HashRouter>\n        <App />\n    </HashRouter>\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n"],"sourceRoot":""}